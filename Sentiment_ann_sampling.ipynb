{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "import keras\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_E6oV3lV.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29720</td>\n",
       "      <td>29720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2242</td>\n",
       "      <td>2242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  tweet\n",
       "label              \n",
       "0      29720  29720\n",
       "1       2242   2242"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = df.query('label==1').sample(frac=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2242, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29720</td>\n",
       "      <td>29720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4484</td>\n",
       "      <td>4484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  tweet\n",
       "label              \n",
       "0      29720  29720\n",
       "1       4484   4484"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_df = pd.concat([df,df1],ignore_index=True)\n",
    "n_df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_class_0, count_class_1 = df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_class_0 =  df.query('label==0')\n",
    "df_class_1 =  df.query('label==1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_class_0_under = df_class_0.sample(count_class_1)\n",
    "df_under = pd.concat([df_class_0_under, df_class_1],ignore_index=True ,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4484, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_under.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2242</td>\n",
       "      <td>2242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2242</td>\n",
       "      <td>2242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  tweet\n",
       "label             \n",
       "0      2242   2242\n",
       "1      2242   2242"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_under.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df_under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df['tweet']\n",
    "Y = df['label']\n",
    "Y_org = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "max_features = 10000\n",
    "tokenizer = Tokenizer(num_words=max_features, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', split=' ', lower=True, char_level=False, oov_token=None)\n",
    "tokenizer.fit_on_texts(X.values)\n",
    "X = tokenizer.texts_to_sequences(X.values)\n",
    "\n",
    "# add padding\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "X = pad_sequences(X, maxlen=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'we all know that the difference between kpekere $ plantain chip na packagingð\\x9f\\x99\\x8c good evening #  ramadan day 14 ð\\x9f\\x8d\\x8fð\\x9f\\x8d\\x89ð\\x9f\\x8d\\x8cð\\x9f\\x8d\\x8dð\\x9f\\x9a¿ð\\x9f\\x98´ð\\x9f\\x95\\x92ð\\x9f\\x8d\\x9bð\\x9f\\x8d\\x97ð\\x9f\\x91\\x8a'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df['tweet'], key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shivam/.conda/envs/my_root/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 35)\n",
    "pca.fit(X)\n",
    "X = pca.transform(X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFQgREYlJBUJERGL6fw7dNZzfePMyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f42fc07c208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.cumsum(pca.explained_variance_ratio_)*100)\n",
    "plt.xlabel(\"No. of components\")\n",
    "plt.ylabel(\"cummulative explained Variance\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.2, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units= 20,kernel_initializer= 'uniform', activation='relu' ,input_dim =X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.add(Dense(units= 20,kernel_initializer= 'uniform', activation='relu'))\n",
    "classifier.add(Dropout(0.1))\n",
    "classifier.add(Dense(units= 20,kernel_initializer= 'uniform', activation='relu'))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(2,kernel_initializer='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shivam/.conda/envs/my_root/lib/python3.6/site-packages/ipykernel_launcher.py:5: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \"\"\"\n",
      "/home/shivam/.conda/envs/my_root/lib/python3.6/site-packages/ipykernel_launcher.py:6: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "y_e = OneHotEncoder()\n",
    "Y_train_org = Y_train\n",
    "Y_test_org = Y_test\n",
    "Y_train = Y_train.reshape(-1, 1)\n",
    "Y_test = Y_test.reshape(-1, 1)\n",
    "y_e.fit(Y_train)\n",
    "Y_train = y_e.transform(Y_train)\n",
    "Y_test = y_e.transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3587x2 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3587 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<897x2 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 897 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3587 samples, validate on 897 samples\n",
      "Epoch 1/300\n",
      "3587/3587 [==============================] - 1s 154us/step - loss: 0.4412 - acc: 0.8037 - val_loss: 0.6969 - val_acc: 0.6945\n",
      "Epoch 2/300\n",
      "3587/3587 [==============================] - 1s 145us/step - loss: 0.4350 - acc: 0.7998 - val_loss: 0.6856 - val_acc: 0.7012\n",
      "Epoch 3/300\n",
      "3587/3587 [==============================] - 1s 145us/step - loss: 0.4387 - acc: 0.7966 - val_loss: 0.7008 - val_acc: 0.7001\n",
      "Epoch 4/300\n",
      "3587/3587 [==============================] - 1s 148us/step - loss: 0.4357 - acc: 0.7986 - val_loss: 0.6958 - val_acc: 0.6912\n",
      "Epoch 5/300\n",
      "3587/3587 [==============================] - 1s 152us/step - loss: 0.4353 - acc: 0.8035 - val_loss: 0.7039 - val_acc: 0.6878\n",
      "Epoch 6/300\n",
      "3587/3587 [==============================] - 1s 151us/step - loss: 0.4347 - acc: 0.7983 - val_loss: 0.7037 - val_acc: 0.6957\n",
      "Epoch 7/300\n",
      "3587/3587 [==============================] - 1s 155us/step - loss: 0.4290 - acc: 0.8062 - val_loss: 0.7219 - val_acc: 0.6878\n",
      "Epoch 8/300\n",
      "3587/3587 [==============================] - 1s 152us/step - loss: 0.4268 - acc: 0.8054 - val_loss: 0.7053 - val_acc: 0.6968\n",
      "Epoch 9/300\n",
      "3587/3587 [==============================] - 1s 158us/step - loss: 0.4312 - acc: 0.8040 - val_loss: 0.7113 - val_acc: 0.6957\n",
      "Epoch 10/300\n",
      "3587/3587 [==============================] - 1s 155us/step - loss: 0.4268 - acc: 0.8081 - val_loss: 0.7088 - val_acc: 0.7012\n",
      "Epoch 11/300\n",
      "3587/3587 [==============================] - 1s 154us/step - loss: 0.4310 - acc: 0.7983 - val_loss: 0.7233 - val_acc: 0.6968\n",
      "Epoch 12/300\n",
      "3587/3587 [==============================] - 1s 153us/step - loss: 0.4293 - acc: 0.8004 - val_loss: 0.7338 - val_acc: 0.6945\n",
      "Epoch 13/300\n",
      "3587/3587 [==============================] - 1s 156us/step - loss: 0.4197 - acc: 0.8069 - val_loss: 0.7209 - val_acc: 0.6968\n",
      "Epoch 14/300\n",
      "3587/3587 [==============================] - 1s 154us/step - loss: 0.4219 - acc: 0.8049 - val_loss: 0.7214 - val_acc: 0.6957\n",
      "Epoch 15/300\n",
      "3587/3587 [==============================] - 1s 155us/step - loss: 0.4229 - acc: 0.8107 - val_loss: 0.7307 - val_acc: 0.6990\n",
      "Epoch 16/300\n",
      "3587/3587 [==============================] - 1s 165us/step - loss: 0.4213 - acc: 0.8053 - val_loss: 0.7219 - val_acc: 0.6878\n",
      "Epoch 17/300\n",
      "3587/3587 [==============================] - 1s 195us/step - loss: 0.4276 - acc: 0.8054 - val_loss: 0.7288 - val_acc: 0.6823\n",
      "Epoch 18/300\n",
      "3587/3587 [==============================] - 1s 192us/step - loss: 0.4204 - acc: 0.8146 - val_loss: 0.7389 - val_acc: 0.6923\n",
      "Epoch 19/300\n",
      "3587/3587 [==============================] - 1s 156us/step - loss: 0.4198 - acc: 0.8101 - val_loss: 0.7226 - val_acc: 0.6973\n",
      "Epoch 20/300\n",
      "3587/3587 [==============================] - 1s 153us/step - loss: 0.4344 - acc: 0.7989 - val_loss: 0.7167 - val_acc: 0.6856\n",
      "Epoch 21/300\n",
      "3587/3587 [==============================] - 1s 155us/step - loss: 0.4148 - acc: 0.8121 - val_loss: 0.7357 - val_acc: 0.6923\n",
      "Epoch 22/300\n",
      "3587/3587 [==============================] - 1s 188us/step - loss: 0.4142 - acc: 0.8107 - val_loss: 0.7241 - val_acc: 0.6957\n",
      "Epoch 23/300\n",
      "3587/3587 [==============================] - 1s 155us/step - loss: 0.4105 - acc: 0.8142 - val_loss: 0.7493 - val_acc: 0.6990\n",
      "Epoch 24/300\n",
      "3587/3587 [==============================] - 1s 155us/step - loss: 0.4159 - acc: 0.8071 - val_loss: 0.7242 - val_acc: 0.6934\n",
      "Epoch 25/300\n",
      "3587/3587 [==============================] - 1s 157us/step - loss: 0.4243 - acc: 0.8082 - val_loss: 0.7365 - val_acc: 0.6901\n",
      "Epoch 26/300\n",
      "3587/3587 [==============================] - 1s 154us/step - loss: 0.4163 - acc: 0.8113 - val_loss: 0.7619 - val_acc: 0.6968\n",
      "Epoch 27/300\n",
      "3587/3587 [==============================] - 1s 186us/step - loss: 0.4148 - acc: 0.8121 - val_loss: 0.7659 - val_acc: 0.6867\n",
      "Epoch 28/300\n",
      "3587/3587 [==============================] - 1s 161us/step - loss: 0.4226 - acc: 0.8089 - val_loss: 0.7394 - val_acc: 0.6979\n",
      "Epoch 29/300\n",
      "3587/3587 [==============================] - 1s 153us/step - loss: 0.4040 - acc: 0.8164 - val_loss: 0.7634 - val_acc: 0.6901\n",
      "Epoch 30/300\n",
      "3587/3587 [==============================] - 1s 183us/step - loss: 0.4160 - acc: 0.8138 - val_loss: 0.7362 - val_acc: 0.6912\n",
      "Epoch 31/300\n",
      "3587/3587 [==============================] - 1s 155us/step - loss: 0.4117 - acc: 0.8166 - val_loss: 0.7528 - val_acc: 0.6912\n",
      "Epoch 32/300\n",
      "3587/3587 [==============================] - 1s 155us/step - loss: 0.4023 - acc: 0.8181 - val_loss: 0.7586 - val_acc: 0.6923\n",
      "Epoch 33/300\n",
      "3587/3587 [==============================] - 1s 161us/step - loss: 0.4080 - acc: 0.8193 - val_loss: 0.7591 - val_acc: 0.6901\n",
      "Epoch 34/300\n",
      "3587/3587 [==============================] - 1s 163us/step - loss: 0.4024 - acc: 0.8233 - val_loss: 0.7685 - val_acc: 0.6934\n",
      "Epoch 35/300\n",
      "3587/3587 [==============================] - 1s 170us/step - loss: 0.4016 - acc: 0.8200 - val_loss: 0.7677 - val_acc: 0.6990\n",
      "Epoch 36/300\n",
      "3587/3587 [==============================] - 1s 154us/step - loss: 0.4003 - acc: 0.8157 - val_loss: 0.7685 - val_acc: 0.6945\n",
      "Epoch 37/300\n",
      "3587/3587 [==============================] - 1s 169us/step - loss: 0.4058 - acc: 0.8175 - val_loss: 0.7670 - val_acc: 0.6934\n",
      "Epoch 38/300\n",
      "3587/3587 [==============================] - 1s 182us/step - loss: 0.4076 - acc: 0.8166 - val_loss: 0.7530 - val_acc: 0.6968\n",
      "Epoch 39/300\n",
      "3587/3587 [==============================] - 1s 180us/step - loss: 0.4088 - acc: 0.8166 - val_loss: 0.7548 - val_acc: 0.6878\n",
      "Epoch 40/300\n",
      "3587/3587 [==============================] - 1s 164us/step - loss: 0.4098 - acc: 0.8135 - val_loss: 0.7663 - val_acc: 0.6890\n",
      "Epoch 41/300\n",
      "3587/3587 [==============================] - 1s 171us/step - loss: 0.4107 - acc: 0.8171 - val_loss: 0.7573 - val_acc: 0.6979\n",
      "Epoch 42/300\n",
      "3587/3587 [==============================] - 1s 162us/step - loss: 0.4040 - acc: 0.8188 - val_loss: 0.7724 - val_acc: 0.6957\n",
      "Epoch 43/300\n",
      "3587/3587 [==============================] - 1s 157us/step - loss: 0.4006 - acc: 0.8154 - val_loss: 0.7629 - val_acc: 0.6912\n",
      "Epoch 44/300\n",
      "3587/3587 [==============================] - 1s 165us/step - loss: 0.4051 - acc: 0.8149 - val_loss: 0.7584 - val_acc: 0.6923\n",
      "Epoch 45/300\n",
      "3587/3587 [==============================] - 1s 202us/step - loss: 0.4035 - acc: 0.8199 - val_loss: 0.7814 - val_acc: 0.6990\n",
      "Epoch 46/300\n",
      "3587/3587 [==============================] - 1s 191us/step - loss: 0.4028 - acc: 0.8182 - val_loss: 0.7764 - val_acc: 0.6957\n",
      "Epoch 47/300\n",
      "3587/3587 [==============================] - 1s 160us/step - loss: 0.3939 - acc: 0.8238 - val_loss: 0.7974 - val_acc: 0.6934\n",
      "Epoch 48/300\n",
      "3587/3587 [==============================] - 1s 166us/step - loss: 0.4045 - acc: 0.8182 - val_loss: 0.7832 - val_acc: 0.6845\n",
      "Epoch 49/300\n",
      "3587/3587 [==============================] - 1s 186us/step - loss: 0.3988 - acc: 0.8152 - val_loss: 0.7915 - val_acc: 0.6878\n",
      "Epoch 50/300\n",
      "3587/3587 [==============================] - 1s 163us/step - loss: 0.3961 - acc: 0.8214 - val_loss: 0.7862 - val_acc: 0.6867\n",
      "Epoch 51/300\n",
      "3587/3587 [==============================] - 1s 161us/step - loss: 0.3969 - acc: 0.8210 - val_loss: 0.8052 - val_acc: 0.6901\n",
      "Epoch 52/300\n",
      "3587/3587 [==============================] - 1s 165us/step - loss: 0.4151 - acc: 0.8141 - val_loss: 0.8132 - val_acc: 0.7035\n",
      "Epoch 53/300\n",
      "3587/3587 [==============================] - 1s 156us/step - loss: 0.3916 - acc: 0.8246 - val_loss: 0.8026 - val_acc: 0.6945\n",
      "Epoch 54/300\n",
      "3587/3587 [==============================] - 1s 203us/step - loss: 0.3918 - acc: 0.8285 - val_loss: 0.8056 - val_acc: 0.6890\n",
      "Epoch 55/300\n",
      "3587/3587 [==============================] - 1s 161us/step - loss: 0.3957 - acc: 0.8216 - val_loss: 0.8135 - val_acc: 0.6968\n",
      "Epoch 56/300\n",
      "3587/3587 [==============================] - 1s 167us/step - loss: 0.4212 - acc: 0.8037 - val_loss: 0.7671 - val_acc: 0.6990\n",
      "Epoch 57/300\n",
      "3587/3587 [==============================] - 1s 157us/step - loss: 0.4043 - acc: 0.8163 - val_loss: 0.7982 - val_acc: 0.6890\n",
      "Epoch 58/300\n",
      "3587/3587 [==============================] - 1s 164us/step - loss: 0.3947 - acc: 0.8233 - val_loss: 0.8026 - val_acc: 0.6878\n",
      "Epoch 59/300\n",
      "3587/3587 [==============================] - 1s 163us/step - loss: 0.3979 - acc: 0.8230 - val_loss: 0.8199 - val_acc: 0.6945\n",
      "Epoch 60/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3587/3587 [==============================] - 1s 147us/step - loss: 0.3918 - acc: 0.8249 - val_loss: 0.8188 - val_acc: 0.6945\n",
      "Epoch 61/300\n",
      "3587/3587 [==============================] - 1s 144us/step - loss: 0.3957 - acc: 0.8177 - val_loss: 0.8171 - val_acc: 0.6957\n",
      "Epoch 62/300\n",
      "3587/3587 [==============================] - 1s 141us/step - loss: 0.3918 - acc: 0.8213 - val_loss: 0.8302 - val_acc: 0.6923\n",
      "Epoch 63/300\n",
      "3587/3587 [==============================] - 1s 141us/step - loss: 0.3933 - acc: 0.8188 - val_loss: 0.8428 - val_acc: 0.6945\n",
      "Epoch 64/300\n",
      "3587/3587 [==============================] - 1s 140us/step - loss: 0.3857 - acc: 0.8249 - val_loss: 0.8266 - val_acc: 0.6867\n",
      "Epoch 65/300\n",
      "3587/3587 [==============================] - 1s 291us/step - loss: 0.3873 - acc: 0.8283 - val_loss: 0.8345 - val_acc: 0.6990\n",
      "Epoch 66/300\n",
      "3587/3587 [==============================] - 1s 185us/step - loss: 0.3806 - acc: 0.8323 - val_loss: 0.8223 - val_acc: 0.6945\n",
      "Epoch 67/300\n",
      "3587/3587 [==============================] - 1s 283us/step - loss: 0.3909 - acc: 0.8219 - val_loss: 0.8361 - val_acc: 0.6856\n",
      "Epoch 68/300\n",
      "3587/3587 [==============================] - 1s 205us/step - loss: 0.4225 - acc: 0.8088 - val_loss: 0.8192 - val_acc: 0.6878\n",
      "Epoch 69/300\n",
      "3587/3587 [==============================] - 1s 163us/step - loss: 0.3965 - acc: 0.8184 - val_loss: 0.8349 - val_acc: 0.6934\n",
      "Epoch 70/300\n",
      "3587/3587 [==============================] - 1s 160us/step - loss: 0.3953 - acc: 0.8188 - val_loss: 0.8434 - val_acc: 0.6934\n",
      "Epoch 71/300\n",
      "3587/3587 [==============================] - 1s 154us/step - loss: 0.3895 - acc: 0.8246 - val_loss: 0.8386 - val_acc: 0.6934\n",
      "Epoch 72/300\n",
      "3587/3587 [==============================] - 1s 183us/step - loss: 0.3930 - acc: 0.8216 - val_loss: 0.8428 - val_acc: 0.6845\n",
      "Epoch 73/300\n",
      "3587/3587 [==============================] - 1s 154us/step - loss: 0.3847 - acc: 0.8276 - val_loss: 0.8648 - val_acc: 0.6968\n",
      "Epoch 74/300\n",
      "3587/3587 [==============================] - 1s 163us/step - loss: 0.3878 - acc: 0.8224 - val_loss: 0.8260 - val_acc: 0.6890\n",
      "Epoch 75/300\n",
      "3587/3587 [==============================] - 1s 181us/step - loss: 0.3858 - acc: 0.8272 - val_loss: 0.8482 - val_acc: 0.6990\n",
      "Epoch 76/300\n",
      "3587/3587 [==============================] - 1s 179us/step - loss: 0.3786 - acc: 0.8336 - val_loss: 0.8895 - val_acc: 0.7046\n",
      "Epoch 77/300\n",
      "3587/3587 [==============================] - 1s 179us/step - loss: 0.3786 - acc: 0.8288 - val_loss: 0.8529 - val_acc: 0.7023\n",
      "Epoch 78/300\n",
      "3587/3587 [==============================] - 1s 187us/step - loss: 0.3896 - acc: 0.8256 - val_loss: 0.8549 - val_acc: 0.6867\n",
      "Epoch 79/300\n",
      "3587/3587 [==============================] - 1s 177us/step - loss: 0.3881 - acc: 0.8230 - val_loss: 0.8118 - val_acc: 0.6979\n",
      "Epoch 80/300\n",
      "3587/3587 [==============================] - 1s 170us/step - loss: 0.3815 - acc: 0.8269 - val_loss: 0.8579 - val_acc: 0.6934\n",
      "Epoch 81/300\n",
      "3587/3587 [==============================] - 1s 189us/step - loss: 0.3851 - acc: 0.8292 - val_loss: 0.8235 - val_acc: 0.6873\n",
      "Epoch 82/300\n",
      "3587/3587 [==============================] - 1s 161us/step - loss: 0.3854 - acc: 0.8266 - val_loss: 0.8710 - val_acc: 0.7035\n",
      "Epoch 83/300\n",
      "3587/3587 [==============================] - 1s 182us/step - loss: 0.3787 - acc: 0.8319 - val_loss: 0.8698 - val_acc: 0.6923\n",
      "Epoch 84/300\n",
      "3587/3587 [==============================] - 1s 173us/step - loss: 0.3782 - acc: 0.8327 - val_loss: 0.8739 - val_acc: 0.7035\n",
      "Epoch 85/300\n",
      "3587/3587 [==============================] - 1s 158us/step - loss: 0.3861 - acc: 0.8285 - val_loss: 0.8938 - val_acc: 0.7001\n",
      "Epoch 86/300\n",
      "3587/3587 [==============================] - 1s 183us/step - loss: 0.3817 - acc: 0.8283 - val_loss: 0.9040 - val_acc: 0.6867\n",
      "Epoch 87/300\n",
      "3587/3587 [==============================] - 1s 178us/step - loss: 0.3831 - acc: 0.8269 - val_loss: 0.8516 - val_acc: 0.6990\n",
      "Epoch 88/300\n",
      "3587/3587 [==============================] - 1s 180us/step - loss: 0.3844 - acc: 0.8266 - val_loss: 0.8541 - val_acc: 0.6934\n",
      "Epoch 89/300\n",
      "3587/3587 [==============================] - 1s 181us/step - loss: 0.3855 - acc: 0.8246 - val_loss: 0.8659 - val_acc: 0.7012\n",
      "Epoch 90/300\n",
      "3587/3587 [==============================] - 1s 179us/step - loss: 0.3832 - acc: 0.8251 - val_loss: 0.8588 - val_acc: 0.7079\n",
      "Epoch 91/300\n",
      "3587/3587 [==============================] - 1s 177us/step - loss: 0.3818 - acc: 0.8252 - val_loss: 0.8629 - val_acc: 0.6990\n",
      "Epoch 92/300\n",
      "3587/3587 [==============================] - 1s 172us/step - loss: 0.3775 - acc: 0.8248 - val_loss: 0.8601 - val_acc: 0.6979\n",
      "Epoch 93/300\n",
      "3587/3587 [==============================] - 1s 174us/step - loss: 0.3872 - acc: 0.8272 - val_loss: 0.8451 - val_acc: 0.7001\n",
      "Epoch 94/300\n",
      "3587/3587 [==============================] - 1s 193us/step - loss: 0.3768 - acc: 0.8327 - val_loss: 0.8524 - val_acc: 0.7001\n",
      "Epoch 95/300\n",
      "3587/3587 [==============================] - 1s 178us/step - loss: 0.3845 - acc: 0.8265 - val_loss: 0.8703 - val_acc: 0.7001\n",
      "Epoch 96/300\n",
      "3587/3587 [==============================] - 1s 182us/step - loss: 0.3763 - acc: 0.8325 - val_loss: 0.8805 - val_acc: 0.6968\n",
      "Epoch 97/300\n",
      "3587/3587 [==============================] - 1s 185us/step - loss: 0.3766 - acc: 0.8302 - val_loss: 0.8687 - val_acc: 0.6957\n",
      "Epoch 98/300\n",
      "3587/3587 [==============================] - 1s 189us/step - loss: 0.3800 - acc: 0.8258 - val_loss: 0.8677 - val_acc: 0.6968\n",
      "Epoch 99/300\n",
      "3587/3587 [==============================] - 1s 162us/step - loss: 0.3818 - acc: 0.8290 - val_loss: 0.8873 - val_acc: 0.6940\n",
      "Epoch 100/300\n",
      "3587/3587 [==============================] - 1s 163us/step - loss: 0.3764 - acc: 0.8341 - val_loss: 0.9306 - val_acc: 0.6990\n",
      "Epoch 101/300\n",
      "3587/3587 [==============================] - 1s 158us/step - loss: 0.3706 - acc: 0.8350 - val_loss: 0.8936 - val_acc: 0.6934\n",
      "Epoch 102/300\n",
      "3587/3587 [==============================] - 1s 166us/step - loss: 0.3775 - acc: 0.8267 - val_loss: 0.9159 - val_acc: 0.7001\n",
      "Epoch 103/300\n",
      "3587/3587 [==============================] - 1s 188us/step - loss: 0.3739 - acc: 0.8355 - val_loss: 0.9055 - val_acc: 0.6990\n",
      "Epoch 104/300\n",
      "3587/3587 [==============================] - 1s 195us/step - loss: 0.3877 - acc: 0.8272 - val_loss: 0.8932 - val_acc: 0.6945\n",
      "Epoch 105/300\n",
      "3587/3587 [==============================] - 1s 194us/step - loss: 0.3810 - acc: 0.8299 - val_loss: 0.8491 - val_acc: 0.6990\n",
      "Epoch 106/300\n",
      "3587/3587 [==============================] - 1s 175us/step - loss: 0.3710 - acc: 0.8308 - val_loss: 0.8966 - val_acc: 0.6957\n",
      "Epoch 107/300\n",
      "3587/3587 [==============================] - 1s 186us/step - loss: 0.3688 - acc: 0.8322 - val_loss: 0.8823 - val_acc: 0.6990\n",
      "Epoch 108/300\n",
      "3587/3587 [==============================] - 1s 194us/step - loss: 0.3804 - acc: 0.8283 - val_loss: 0.8822 - val_acc: 0.7012\n",
      "Epoch 109/300\n",
      "3587/3587 [==============================] - 1s 163us/step - loss: 0.3764 - acc: 0.8260 - val_loss: 0.9252 - val_acc: 0.7057\n",
      "Epoch 110/300\n",
      "3587/3587 [==============================] - 1s 184us/step - loss: 0.3675 - acc: 0.8344 - val_loss: 0.9153 - val_acc: 0.6979\n",
      "Epoch 111/300\n",
      "3587/3587 [==============================] - 1s 190us/step - loss: 0.3736 - acc: 0.8333 - val_loss: 0.9155 - val_acc: 0.6990\n",
      "Epoch 112/300\n",
      "3587/3587 [==============================] - 1s 158us/step - loss: 0.3795 - acc: 0.8291 - val_loss: 0.8785 - val_acc: 0.6856\n",
      "Epoch 113/300\n",
      "3587/3587 [==============================] - 1s 193us/step - loss: 0.3735 - acc: 0.8330 - val_loss: 0.8815 - val_acc: 0.6945\n",
      "Epoch 114/300\n",
      "3587/3587 [==============================] - 1s 186us/step - loss: 0.3705 - acc: 0.8299 - val_loss: 0.8957 - val_acc: 0.6968\n",
      "Epoch 115/300\n",
      "3587/3587 [==============================] - 1s 183us/step - loss: 0.3751 - acc: 0.8319 - val_loss: 0.8845 - val_acc: 0.6901\n",
      "Epoch 116/300\n",
      "3587/3587 [==============================] - 1s 176us/step - loss: 0.3711 - acc: 0.8336 - val_loss: 0.8809 - val_acc: 0.7057\n",
      "Epoch 117/300\n",
      "3587/3587 [==============================] - 1s 181us/step - loss: 0.3696 - acc: 0.8347 - val_loss: 0.8976 - val_acc: 0.7012\n",
      "Epoch 118/300\n",
      "3587/3587 [==============================] - 1s 181us/step - loss: 0.3682 - acc: 0.8333 - val_loss: 0.9128 - val_acc: 0.7001\n",
      "Epoch 119/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3587/3587 [==============================] - 1s 141us/step - loss: 0.3680 - acc: 0.8347 - val_loss: 0.8833 - val_acc: 0.6934\n",
      "Epoch 120/300\n",
      "3587/3587 [==============================] - 1s 182us/step - loss: 0.3687 - acc: 0.8316 - val_loss: 0.9000 - val_acc: 0.6934\n",
      "Epoch 121/300\n",
      "3587/3587 [==============================] - 1s 180us/step - loss: 0.3714 - acc: 0.8291 - val_loss: 0.9036 - val_acc: 0.6923\n",
      "Epoch 122/300\n",
      "3587/3587 [==============================] - 1s 149us/step - loss: 0.3790 - acc: 0.8290 - val_loss: 0.8821 - val_acc: 0.6934\n",
      "Epoch 123/300\n",
      "3587/3587 [==============================] - 1s 150us/step - loss: 0.3751 - acc: 0.8325 - val_loss: 0.8717 - val_acc: 0.7023\n",
      "Epoch 124/300\n",
      "3587/3587 [==============================] - 1s 152us/step - loss: 0.3690 - acc: 0.8333 - val_loss: 0.8871 - val_acc: 0.6990\n",
      "Epoch 125/300\n",
      "3587/3587 [==============================] - 1s 154us/step - loss: 0.3801 - acc: 0.8285 - val_loss: 0.8694 - val_acc: 0.7035\n",
      "Epoch 126/300\n",
      "3587/3587 [==============================] - 1s 154us/step - loss: 0.3681 - acc: 0.8338 - val_loss: 0.8826 - val_acc: 0.6990\n",
      "Epoch 127/300\n",
      "3587/3587 [==============================] - 1s 152us/step - loss: 0.3746 - acc: 0.8330 - val_loss: 0.8952 - val_acc: 0.6945\n",
      "Epoch 128/300\n",
      "3587/3587 [==============================] - 1s 151us/step - loss: 0.3737 - acc: 0.8325 - val_loss: 0.9055 - val_acc: 0.7001\n",
      "Epoch 129/300\n",
      "3587/3587 [==============================] - 1s 156us/step - loss: 0.3676 - acc: 0.8366 - val_loss: 0.9068 - val_acc: 0.6945\n",
      "Epoch 130/300\n",
      "3587/3587 [==============================] - 1s 173us/step - loss: 0.3614 - acc: 0.8357 - val_loss: 0.9355 - val_acc: 0.7012\n",
      "Epoch 131/300\n",
      "3587/3587 [==============================] - 1s 153us/step - loss: 0.3620 - acc: 0.8372 - val_loss: 0.9430 - val_acc: 0.6968\n",
      "Epoch 132/300\n",
      "3587/3587 [==============================] - 1s 152us/step - loss: 0.3653 - acc: 0.8377 - val_loss: 0.9537 - val_acc: 0.6923\n",
      "Epoch 133/300\n",
      "3587/3587 [==============================] - 1s 151us/step - loss: 0.3655 - acc: 0.8311 - val_loss: 0.9602 - val_acc: 0.6957\n",
      "Epoch 134/300\n",
      "3587/3587 [==============================] - 1s 155us/step - loss: 0.3633 - acc: 0.8366 - val_loss: 0.9401 - val_acc: 0.6979\n",
      "Epoch 135/300\n",
      "3587/3587 [==============================] - 1s 152us/step - loss: 0.3642 - acc: 0.8375 - val_loss: 0.9342 - val_acc: 0.6934\n",
      "Epoch 136/300\n",
      "3587/3587 [==============================] - 1s 152us/step - loss: 0.3524 - acc: 0.8411 - val_loss: 0.9744 - val_acc: 0.6934\n",
      "Epoch 137/300\n",
      "3587/3587 [==============================] - 1s 151us/step - loss: 0.3677 - acc: 0.8361 - val_loss: 0.9540 - val_acc: 0.6979\n",
      "Epoch 138/300\n",
      "3587/3587 [==============================] - 1s 154us/step - loss: 0.3775 - acc: 0.8280 - val_loss: 0.9053 - val_acc: 0.6979\n",
      "Epoch 139/300\n",
      "3587/3587 [==============================] - 1s 153us/step - loss: 0.3546 - acc: 0.8405 - val_loss: 0.9562 - val_acc: 0.6878\n",
      "Epoch 140/300\n",
      "3587/3587 [==============================] - 1s 160us/step - loss: 0.3758 - acc: 0.8325 - val_loss: 0.9217 - val_acc: 0.6912\n",
      "Epoch 141/300\n",
      "3587/3587 [==============================] - 1s 151us/step - loss: 0.3607 - acc: 0.8366 - val_loss: 0.9404 - val_acc: 0.7012\n",
      "Epoch 142/300\n",
      "3587/3587 [==============================] - 1s 154us/step - loss: 0.3543 - acc: 0.8408 - val_loss: 0.9658 - val_acc: 0.6957\n",
      "Epoch 143/300\n",
      "3587/3587 [==============================] - 1s 152us/step - loss: 0.3999 - acc: 0.8237 - val_loss: 0.9063 - val_acc: 0.6878\n",
      "Epoch 144/300\n",
      "3587/3587 [==============================] - 1s 243us/step - loss: 0.3881 - acc: 0.8221 - val_loss: 0.9418 - val_acc: 0.6867\n",
      "Epoch 145/300\n",
      "3587/3587 [==============================] - 1s 245us/step - loss: 0.3694 - acc: 0.8336 - val_loss: 0.9026 - val_acc: 0.6968\n",
      "Epoch 146/300\n",
      "3587/3587 [==============================] - 1s 214us/step - loss: 0.3649 - acc: 0.8375 - val_loss: 0.9301 - val_acc: 0.6968\n",
      "Epoch 147/300\n",
      "3587/3587 [==============================] - 1s 203us/step - loss: 0.3593 - acc: 0.8405 - val_loss: 0.9311 - val_acc: 0.6945\n",
      "Epoch 148/300\n",
      "3587/3587 [==============================] - 1s 212us/step - loss: 0.3661 - acc: 0.8397 - val_loss: 0.9308 - val_acc: 0.6957\n",
      "Epoch 149/300\n",
      "3587/3587 [==============================] - 1s 248us/step - loss: 0.3641 - acc: 0.8369 - val_loss: 0.9331 - val_acc: 0.6968\n",
      "Epoch 150/300\n",
      "3587/3587 [==============================] - 1s 205us/step - loss: 0.3572 - acc: 0.8383 - val_loss: 0.9623 - val_acc: 0.6890\n",
      "Epoch 151/300\n",
      "3587/3587 [==============================] - 1s 194us/step - loss: 0.3607 - acc: 0.8391 - val_loss: 0.9935 - val_acc: 0.6968\n",
      "Epoch 152/300\n",
      "3587/3587 [==============================] - 1s 176us/step - loss: 0.3708 - acc: 0.8325 - val_loss: 0.9895 - val_acc: 0.6990\n",
      "Epoch 153/300\n",
      "3587/3587 [==============================] - 1s 185us/step - loss: 0.3528 - acc: 0.8397 - val_loss: 0.9892 - val_acc: 0.6912\n",
      "Epoch 154/300\n",
      "3587/3587 [==============================] - 1s 189us/step - loss: 0.3586 - acc: 0.8417 - val_loss: 0.9690 - val_acc: 0.7035\n",
      "Epoch 155/300\n",
      "3587/3587 [==============================] - 1s 187us/step - loss: 0.3616 - acc: 0.8394 - val_loss: 0.9468 - val_acc: 0.7012\n",
      "Epoch 156/300\n",
      "3587/3587 [==============================] - 1s 177us/step - loss: 0.3549 - acc: 0.8433 - val_loss: 0.9810 - val_acc: 0.6934\n",
      "Epoch 157/300\n",
      "3587/3587 [==============================] - 1s 173us/step - loss: 0.3592 - acc: 0.8361 - val_loss: 0.9618 - val_acc: 0.6856\n",
      "Epoch 158/300\n",
      "3587/3587 [==============================] - 1s 186us/step - loss: 0.3591 - acc: 0.8408 - val_loss: 0.9884 - val_acc: 0.7023\n",
      "Epoch 159/300\n",
      "3587/3587 [==============================] - 1s 174us/step - loss: 0.3636 - acc: 0.8389 - val_loss: 0.9337 - val_acc: 0.6934\n",
      "Epoch 160/300\n",
      "3587/3587 [==============================] - 1s 184us/step - loss: 0.3640 - acc: 0.8338 - val_loss: 0.9560 - val_acc: 0.6901\n",
      "Epoch 161/300\n",
      "3587/3587 [==============================] - 1s 179us/step - loss: 0.3643 - acc: 0.8366 - val_loss: 0.9398 - val_acc: 0.7113\n",
      "Epoch 162/300\n",
      "3587/3587 [==============================] - 1s 158us/step - loss: 0.3537 - acc: 0.8422 - val_loss: 0.9551 - val_acc: 0.6968\n",
      "Epoch 163/300\n",
      "3587/3587 [==============================] - 1s 189us/step - loss: 0.3550 - acc: 0.8372 - val_loss: 0.9690 - val_acc: 0.6912\n",
      "Epoch 164/300\n",
      "3587/3587 [==============================] - 1s 217us/step - loss: 0.3648 - acc: 0.8372 - val_loss: 0.9618 - val_acc: 0.7023\n",
      "Epoch 165/300\n",
      "3587/3587 [==============================] - 1s 171us/step - loss: 0.3600 - acc: 0.8325 - val_loss: 1.0058 - val_acc: 0.6945\n",
      "Epoch 166/300\n",
      "3587/3587 [==============================] - 1s 342us/step - loss: 0.3543 - acc: 0.8419 - val_loss: 0.9799 - val_acc: 0.7035\n",
      "Epoch 167/300\n",
      "3587/3587 [==============================] - 1s 180us/step - loss: 0.3657 - acc: 0.8383 - val_loss: 0.9557 - val_acc: 0.6979\n",
      "Epoch 168/300\n",
      "3587/3587 [==============================] - 1s 187us/step - loss: 0.3566 - acc: 0.8389 - val_loss: 0.9916 - val_acc: 0.6945\n",
      "Epoch 169/300\n",
      "3587/3587 [==============================] - 1s 164us/step - loss: 0.3751 - acc: 0.8273 - val_loss: 0.9640 - val_acc: 0.6979\n",
      "Epoch 170/300\n",
      "3587/3587 [==============================] - 1s 163us/step - loss: 0.3526 - acc: 0.8417 - val_loss: 0.9806 - val_acc: 0.6979\n",
      "Epoch 171/300\n",
      "3587/3587 [==============================] - 1s 209us/step - loss: 0.3605 - acc: 0.8383 - val_loss: 0.9588 - val_acc: 0.6968\n",
      "Epoch 172/300\n",
      "3587/3587 [==============================] - 1s 184us/step - loss: 0.3549 - acc: 0.8397 - val_loss: 1.0008 - val_acc: 0.6957\n",
      "Epoch 173/300\n",
      "3587/3587 [==============================] - 1s 166us/step - loss: 0.3536 - acc: 0.8425 - val_loss: 0.9980 - val_acc: 0.7023\n",
      "Epoch 174/300\n",
      "3587/3587 [==============================] - 1s 190us/step - loss: 0.3745 - acc: 0.8344 - val_loss: 0.9539 - val_acc: 0.7023\n",
      "Epoch 175/300\n",
      "3587/3587 [==============================] - 1s 187us/step - loss: 0.3782 - acc: 0.8299 - val_loss: 0.9796 - val_acc: 0.6901\n",
      "Epoch 176/300\n",
      "3587/3587 [==============================] - 1s 184us/step - loss: 0.3574 - acc: 0.8366 - val_loss: 1.0118 - val_acc: 0.7113\n",
      "Epoch 177/300\n",
      "3587/3587 [==============================] - 1s 165us/step - loss: 0.3550 - acc: 0.8397 - val_loss: 0.9804 - val_acc: 0.7012\n",
      "Epoch 178/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3587/3587 [==============================] - 1s 185us/step - loss: 0.3548 - acc: 0.8428 - val_loss: 0.9943 - val_acc: 0.7113\n",
      "Epoch 179/300\n",
      "3587/3587 [==============================] - 1s 172us/step - loss: 0.3453 - acc: 0.8464 - val_loss: 0.9822 - val_acc: 0.7046\n",
      "Epoch 180/300\n",
      "3587/3587 [==============================] - 1s 153us/step - loss: 0.3890 - acc: 0.8249 - val_loss: 0.9601 - val_acc: 0.7001\n",
      "Epoch 181/300\n",
      "3587/3587 [==============================] - 1s 193us/step - loss: 0.3741 - acc: 0.8319 - val_loss: 0.9927 - val_acc: 0.6945\n",
      "Epoch 182/300\n",
      "3587/3587 [==============================] - 1s 175us/step - loss: 0.3655 - acc: 0.8386 - val_loss: 0.9787 - val_acc: 0.7001\n",
      "Epoch 183/300\n",
      "3587/3587 [==============================] - 1s 180us/step - loss: 0.3660 - acc: 0.8375 - val_loss: 0.9860 - val_acc: 0.6957\n",
      "Epoch 184/300\n",
      "3587/3587 [==============================] - 1s 179us/step - loss: 0.3530 - acc: 0.8433 - val_loss: 1.0024 - val_acc: 0.6923\n",
      "Epoch 185/300\n",
      "3587/3587 [==============================] - 1s 172us/step - loss: 0.3548 - acc: 0.8414 - val_loss: 0.9633 - val_acc: 0.6923\n",
      "Epoch 186/300\n",
      "3587/3587 [==============================] - 1s 180us/step - loss: 0.3599 - acc: 0.8422 - val_loss: 0.9689 - val_acc: 0.6968\n",
      "Epoch 187/300\n",
      "3587/3587 [==============================] - 1s 162us/step - loss: 0.3558 - acc: 0.8405 - val_loss: 0.9646 - val_acc: 0.6979\n",
      "Epoch 188/300\n",
      "3587/3587 [==============================] - 1s 184us/step - loss: 0.3574 - acc: 0.8391 - val_loss: 0.9838 - val_acc: 0.7057\n",
      "Epoch 189/300\n",
      "3587/3587 [==============================] - 1s 178us/step - loss: 0.3595 - acc: 0.8386 - val_loss: 0.9877 - val_acc: 0.7035\n",
      "Epoch 190/300\n",
      "3587/3587 [==============================] - 1s 159us/step - loss: 0.3592 - acc: 0.8397 - val_loss: 0.9686 - val_acc: 0.6990\n",
      "Epoch 191/300\n",
      "3587/3587 [==============================] - 1s 162us/step - loss: 0.3497 - acc: 0.8450 - val_loss: 0.9832 - val_acc: 0.7001\n",
      "Epoch 192/300\n",
      "3587/3587 [==============================] - 1s 161us/step - loss: 0.3498 - acc: 0.8428 - val_loss: 1.0032 - val_acc: 0.6979\n",
      "Epoch 193/300\n",
      "3587/3587 [==============================] - 1s 163us/step - loss: 0.3455 - acc: 0.8442 - val_loss: 1.0249 - val_acc: 0.6979\n",
      "Epoch 194/300\n",
      "3587/3587 [==============================] - 1s 195us/step - loss: 0.3610 - acc: 0.8394 - val_loss: 0.9890 - val_acc: 0.7023\n",
      "Epoch 195/300\n",
      "3587/3587 [==============================] - 1s 187us/step - loss: 0.3436 - acc: 0.8489 - val_loss: 1.0536 - val_acc: 0.7012\n",
      "Epoch 196/300\n",
      "3587/3587 [==============================] - 1s 181us/step - loss: 0.3394 - acc: 0.8514 - val_loss: 0.9954 - val_acc: 0.7046\n",
      "Epoch 197/300\n",
      "3587/3587 [==============================] - 1s 180us/step - loss: 0.3431 - acc: 0.8495 - val_loss: 1.0294 - val_acc: 0.7035\n",
      "Epoch 198/300\n",
      "3587/3587 [==============================] - 1s 180us/step - loss: 0.3479 - acc: 0.8425 - val_loss: 1.0126 - val_acc: 0.7079\n",
      "Epoch 199/300\n",
      "3587/3587 [==============================] - 1s 179us/step - loss: 0.3523 - acc: 0.8380 - val_loss: 1.0046 - val_acc: 0.7057\n",
      "Epoch 200/300\n",
      "3587/3587 [==============================] - 1s 166us/step - loss: 0.3516 - acc: 0.8417 - val_loss: 1.0254 - val_acc: 0.6934\n",
      "Epoch 201/300\n",
      "3587/3587 [==============================] - 1s 185us/step - loss: 0.3725 - acc: 0.8319 - val_loss: 0.9667 - val_acc: 0.7012\n",
      "Epoch 202/300\n",
      "3587/3587 [==============================] - 1s 183us/step - loss: 0.3626 - acc: 0.8400 - val_loss: 0.9713 - val_acc: 0.6945\n",
      "Epoch 203/300\n",
      "3587/3587 [==============================] - 1s 178us/step - loss: 0.3448 - acc: 0.8442 - val_loss: 0.9979 - val_acc: 0.7035\n",
      "Epoch 204/300\n",
      "3587/3587 [==============================] - 1s 179us/step - loss: 0.3553 - acc: 0.8436 - val_loss: 0.9833 - val_acc: 0.7046\n",
      "Epoch 205/300\n",
      "3587/3587 [==============================] - 1s 167us/step - loss: 0.3500 - acc: 0.8442 - val_loss: 0.9984 - val_acc: 0.6945\n",
      "Epoch 206/300\n",
      "3587/3587 [==============================] - 1s 186us/step - loss: 0.3484 - acc: 0.8468 - val_loss: 1.0114 - val_acc: 0.6990\n",
      "Epoch 207/300\n",
      "3587/3587 [==============================] - 1s 162us/step - loss: 0.3428 - acc: 0.8444 - val_loss: 1.0272 - val_acc: 0.7035\n",
      "Epoch 208/300\n",
      "3587/3587 [==============================] - 1s 190us/step - loss: 0.3507 - acc: 0.8458 - val_loss: 1.0191 - val_acc: 0.6957\n",
      "Epoch 209/300\n",
      "3587/3587 [==============================] - 1s 178us/step - loss: 0.3532 - acc: 0.8443 - val_loss: 0.9858 - val_acc: 0.7023\n",
      "Epoch 210/300\n",
      "3587/3587 [==============================] - 1s 163us/step - loss: 0.3605 - acc: 0.8361 - val_loss: 0.9642 - val_acc: 0.7035\n",
      "Epoch 211/300\n",
      "3587/3587 [==============================] - 1s 177us/step - loss: 0.3452 - acc: 0.8447 - val_loss: 0.9846 - val_acc: 0.7046\n",
      "Epoch 212/300\n",
      "3587/3587 [==============================] - 1s 180us/step - loss: 0.3470 - acc: 0.8433 - val_loss: 0.9758 - val_acc: 0.6979\n",
      "Epoch 213/300\n",
      "3587/3587 [==============================] - 1s 190us/step - loss: 0.3433 - acc: 0.8456 - val_loss: 1.0314 - val_acc: 0.6968\n",
      "Epoch 214/300\n",
      "3587/3587 [==============================] - 1s 173us/step - loss: 0.3399 - acc: 0.8472 - val_loss: 1.0092 - val_acc: 0.6945\n",
      "Epoch 215/300\n",
      "3587/3587 [==============================] - 1s 185us/step - loss: 0.3602 - acc: 0.8403 - val_loss: 0.9740 - val_acc: 0.7012\n",
      "Epoch 216/300\n",
      "3587/3587 [==============================] - 1s 180us/step - loss: 0.3380 - acc: 0.8461 - val_loss: 1.0136 - val_acc: 0.7001\n",
      "Epoch 217/300\n",
      "3587/3587 [==============================] - 1s 179us/step - loss: 0.3512 - acc: 0.8394 - val_loss: 1.0172 - val_acc: 0.7023\n",
      "Epoch 218/300\n",
      "3587/3587 [==============================] - 1s 184us/step - loss: 0.3464 - acc: 0.8444 - val_loss: 0.9846 - val_acc: 0.6979\n",
      "Epoch 219/300\n",
      "3587/3587 [==============================] - 1s 179us/step - loss: 0.3416 - acc: 0.8467 - val_loss: 1.0193 - val_acc: 0.7101\n",
      "Epoch 220/300\n",
      "3587/3587 [==============================] - 1s 182us/step - loss: 0.3486 - acc: 0.8408 - val_loss: 1.0528 - val_acc: 0.7035\n",
      "Epoch 221/300\n",
      "3587/3587 [==============================] - 1s 185us/step - loss: 0.3491 - acc: 0.8403 - val_loss: 1.0043 - val_acc: 0.7012\n",
      "Epoch 222/300\n",
      "3587/3587 [==============================] - 1s 180us/step - loss: 0.3513 - acc: 0.8383 - val_loss: 1.0138 - val_acc: 0.7135\n",
      "Epoch 223/300\n",
      "3587/3587 [==============================] - 1s 182us/step - loss: 0.3487 - acc: 0.8414 - val_loss: 0.9795 - val_acc: 0.7057\n",
      "Epoch 224/300\n",
      "3587/3587 [==============================] - 1s 177us/step - loss: 0.3309 - acc: 0.8506 - val_loss: 1.0371 - val_acc: 0.6968\n",
      "Epoch 225/300\n",
      "3587/3587 [==============================] - 1s 181us/step - loss: 0.3396 - acc: 0.8444 - val_loss: 1.0101 - val_acc: 0.7012\n",
      "Epoch 226/300\n",
      "3587/3587 [==============================] - 1s 182us/step - loss: 0.3504 - acc: 0.8414 - val_loss: 1.0277 - val_acc: 0.6890\n",
      "Epoch 227/300\n",
      "3587/3587 [==============================] - 1s 184us/step - loss: 0.3441 - acc: 0.8430 - val_loss: 1.0221 - val_acc: 0.6990\n",
      "Epoch 228/300\n",
      "3587/3587 [==============================] - 1s 183us/step - loss: 0.3480 - acc: 0.8461 - val_loss: 1.0713 - val_acc: 0.6979\n",
      "Epoch 229/300\n",
      "3587/3587 [==============================] - 1s 177us/step - loss: 0.3481 - acc: 0.8444 - val_loss: 1.0291 - val_acc: 0.7057\n",
      "Epoch 230/300\n",
      "3587/3587 [==============================] - 1s 183us/step - loss: 0.3493 - acc: 0.8442 - val_loss: 1.0431 - val_acc: 0.7057\n",
      "Epoch 231/300\n",
      "3587/3587 [==============================] - 1s 184us/step - loss: 0.3519 - acc: 0.8379 - val_loss: 1.0356 - val_acc: 0.6934\n",
      "Epoch 232/300\n",
      "3587/3587 [==============================] - 1s 185us/step - loss: 0.3469 - acc: 0.8458 - val_loss: 1.0423 - val_acc: 0.7035\n",
      "Epoch 233/300\n",
      "3587/3587 [==============================] - 1s 181us/step - loss: 0.3383 - acc: 0.8506 - val_loss: 1.0358 - val_acc: 0.7035\n",
      "Epoch 234/300\n",
      "3587/3587 [==============================] - 1s 183us/step - loss: 0.3464 - acc: 0.8469 - val_loss: 1.0744 - val_acc: 0.6990\n",
      "Epoch 235/300\n",
      "3587/3587 [==============================] - 1s 186us/step - loss: 0.3477 - acc: 0.8439 - val_loss: 1.0357 - val_acc: 0.7023\n",
      "Epoch 236/300\n",
      "3587/3587 [==============================] - 1s 183us/step - loss: 0.3360 - acc: 0.8483 - val_loss: 1.0455 - val_acc: 0.7001\n",
      "Epoch 237/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3587/3587 [==============================] - 1s 188us/step - loss: 0.3360 - acc: 0.8458 - val_loss: 1.0655 - val_acc: 0.7012\n",
      "Epoch 238/300\n",
      "3587/3587 [==============================] - 1s 160us/step - loss: 0.3395 - acc: 0.8467 - val_loss: 1.0564 - val_acc: 0.7012\n",
      "Epoch 239/300\n",
      "3587/3587 [==============================] - 1s 182us/step - loss: 0.3574 - acc: 0.8403 - val_loss: 1.0192 - val_acc: 0.7113\n",
      "Epoch 240/300\n",
      "3587/3587 [==============================] - 1s 165us/step - loss: 0.3513 - acc: 0.8430 - val_loss: 1.0233 - val_acc: 0.6934\n",
      "Epoch 241/300\n",
      "3587/3587 [==============================] - 1s 180us/step - loss: 0.3589 - acc: 0.8422 - val_loss: 1.0288 - val_acc: 0.7001\n",
      "Epoch 242/300\n",
      "3587/3587 [==============================] - 1s 169us/step - loss: 0.3524 - acc: 0.8394 - val_loss: 1.0146 - val_acc: 0.7001\n",
      "Epoch 243/300\n",
      "3587/3587 [==============================] - 1s 179us/step - loss: 0.3408 - acc: 0.8475 - val_loss: 1.0275 - val_acc: 0.7012\n",
      "Epoch 244/300\n",
      "3587/3587 [==============================] - 1s 184us/step - loss: 0.3307 - acc: 0.8522 - val_loss: 1.0545 - val_acc: 0.7023\n",
      "Epoch 245/300\n",
      "3587/3587 [==============================] - 1s 177us/step - loss: 0.3414 - acc: 0.8461 - val_loss: 1.0400 - val_acc: 0.7046\n",
      "Epoch 246/300\n",
      "3587/3587 [==============================] - 1s 179us/step - loss: 0.3324 - acc: 0.8492 - val_loss: 1.0469 - val_acc: 0.7001\n",
      "Epoch 247/300\n",
      "3587/3587 [==============================] - 1s 170us/step - loss: 0.3465 - acc: 0.8447 - val_loss: 1.0123 - val_acc: 0.7012\n",
      "Epoch 248/300\n",
      "3587/3587 [==============================] - 1s 174us/step - loss: 0.3400 - acc: 0.8506 - val_loss: 1.0350 - val_acc: 0.7012\n",
      "Epoch 249/300\n",
      "3587/3587 [==============================] - 1s 183us/step - loss: 0.3425 - acc: 0.8500 - val_loss: 1.0474 - val_acc: 0.6968\n",
      "Epoch 250/300\n",
      "3587/3587 [==============================] - 1s 182us/step - loss: 0.3380 - acc: 0.8495 - val_loss: 1.0035 - val_acc: 0.7135\n",
      "Epoch 251/300\n",
      "3587/3587 [==============================] - 1s 177us/step - loss: 0.3449 - acc: 0.8458 - val_loss: 1.0498 - val_acc: 0.7046\n",
      "Epoch 252/300\n",
      "3587/3587 [==============================] - 1s 183us/step - loss: 0.3394 - acc: 0.8492 - val_loss: 1.0498 - val_acc: 0.7079\n",
      "Epoch 253/300\n",
      "3587/3587 [==============================] - 1s 180us/step - loss: 0.3468 - acc: 0.8439 - val_loss: 1.0557 - val_acc: 0.6945\n",
      "Epoch 254/300\n",
      "3587/3587 [==============================] - 1s 177us/step - loss: 0.3383 - acc: 0.8430 - val_loss: 1.1077 - val_acc: 0.7012\n",
      "Epoch 255/300\n",
      "3587/3587 [==============================] - 1s 175us/step - loss: 0.3374 - acc: 0.8469 - val_loss: 1.0678 - val_acc: 0.6968\n",
      "Epoch 256/300\n",
      "3587/3587 [==============================] - 1s 187us/step - loss: 0.3420 - acc: 0.8439 - val_loss: 1.0279 - val_acc: 0.6990\n",
      "Epoch 257/300\n",
      "3587/3587 [==============================] - 1s 180us/step - loss: 0.3432 - acc: 0.8475 - val_loss: 1.0509 - val_acc: 0.7046\n",
      "Epoch 258/300\n",
      "3587/3587 [==============================] - 1s 175us/step - loss: 0.3370 - acc: 0.8489 - val_loss: 1.0480 - val_acc: 0.7046\n",
      "Epoch 259/300\n",
      "3587/3587 [==============================] - 1s 184us/step - loss: 0.3315 - acc: 0.8528 - val_loss: 1.0295 - val_acc: 0.7046\n",
      "Epoch 260/300\n",
      "3587/3587 [==============================] - 1s 175us/step - loss: 0.3392 - acc: 0.8483 - val_loss: 1.0695 - val_acc: 0.7012\n",
      "Epoch 261/300\n",
      "3587/3587 [==============================] - 1s 213us/step - loss: 0.3492 - acc: 0.8456 - val_loss: 1.0564 - val_acc: 0.7090\n",
      "Epoch 262/300\n",
      "3587/3587 [==============================] - 1s 205us/step - loss: 0.3625 - acc: 0.8397 - val_loss: 1.0696 - val_acc: 0.7046\n",
      "Epoch 263/300\n",
      "3587/3587 [==============================] - 1s 300us/step - loss: 0.3443 - acc: 0.8436 - val_loss: 1.0430 - val_acc: 0.7057\n",
      "Epoch 264/300\n",
      "3587/3587 [==============================] - 1s 192us/step - loss: 0.3399 - acc: 0.8483 - val_loss: 1.0695 - val_acc: 0.7090\n",
      "Epoch 265/300\n",
      "3587/3587 [==============================] - 1s 195us/step - loss: 0.3387 - acc: 0.8478 - val_loss: 1.0851 - val_acc: 0.7046\n",
      "Epoch 266/300\n",
      "3587/3587 [==============================] - 1s 183us/step - loss: 0.3322 - acc: 0.8481 - val_loss: 1.0759 - val_acc: 0.7023\n",
      "Epoch 267/300\n",
      "3587/3587 [==============================] - 1s 179us/step - loss: 0.3314 - acc: 0.8514 - val_loss: 1.0518 - val_acc: 0.7046\n",
      "Epoch 268/300\n",
      "3587/3587 [==============================] - 1s 175us/step - loss: 0.3251 - acc: 0.8531 - val_loss: 1.1175 - val_acc: 0.7046\n",
      "Epoch 269/300\n",
      "3587/3587 [==============================] - 1s 183us/step - loss: 0.3426 - acc: 0.8461 - val_loss: 1.0744 - val_acc: 0.7035\n",
      "Epoch 270/300\n",
      "3587/3587 [==============================] - 1s 183us/step - loss: 0.3373 - acc: 0.8475 - val_loss: 1.0533 - val_acc: 0.7046\n",
      "Epoch 271/300\n",
      "3587/3587 [==============================] - 1s 180us/step - loss: 0.3434 - acc: 0.8436 - val_loss: 1.0661 - val_acc: 0.7068\n",
      "Epoch 272/300\n",
      "3587/3587 [==============================] - 1s 178us/step - loss: 0.3369 - acc: 0.8482 - val_loss: 1.0873 - val_acc: 0.7023\n",
      "Epoch 273/300\n",
      "3587/3587 [==============================] - 1s 181us/step - loss: 0.3378 - acc: 0.8472 - val_loss: 1.0723 - val_acc: 0.6957\n",
      "Epoch 274/300\n",
      "3587/3587 [==============================] - 1s 181us/step - loss: 0.3409 - acc: 0.8444 - val_loss: 1.0985 - val_acc: 0.7057\n",
      "Epoch 275/300\n",
      "3587/3587 [==============================] - 1s 172us/step - loss: 0.3416 - acc: 0.8467 - val_loss: 1.0915 - val_acc: 0.7012\n",
      "Epoch 276/300\n",
      "3587/3587 [==============================] - 1s 180us/step - loss: 0.3312 - acc: 0.8509 - val_loss: 1.0807 - val_acc: 0.7079\n",
      "Epoch 277/300\n",
      "3587/3587 [==============================] - 1s 180us/step - loss: 0.3402 - acc: 0.8444 - val_loss: 1.0806 - val_acc: 0.7046\n",
      "Epoch 278/300\n",
      "3587/3587 [==============================] - 1s 179us/step - loss: 0.3410 - acc: 0.8469 - val_loss: 1.0475 - val_acc: 0.6979\n",
      "Epoch 279/300\n",
      "3587/3587 [==============================] - 1s 185us/step - loss: 0.3349 - acc: 0.8464 - val_loss: 1.0445 - val_acc: 0.7068\n",
      "Epoch 280/300\n",
      "3587/3587 [==============================] - 1s 182us/step - loss: 0.3388 - acc: 0.8453 - val_loss: 1.0825 - val_acc: 0.6957\n",
      "Epoch 281/300\n",
      "3587/3587 [==============================] - 1s 183us/step - loss: 0.3452 - acc: 0.8428 - val_loss: 1.0884 - val_acc: 0.7046\n",
      "Epoch 282/300\n",
      "3587/3587 [==============================] - 1s 165us/step - loss: 0.3301 - acc: 0.8495 - val_loss: 1.0897 - val_acc: 0.7001\n",
      "Epoch 283/300\n",
      "3587/3587 [==============================] - 1s 164us/step - loss: 0.3347 - acc: 0.8497 - val_loss: 1.0983 - val_acc: 0.7090\n",
      "Epoch 284/300\n",
      "3587/3587 [==============================] - 1s 166us/step - loss: 0.3359 - acc: 0.8506 - val_loss: 1.1498 - val_acc: 0.7012\n",
      "Epoch 285/300\n",
      "3587/3587 [==============================] - 1s 165us/step - loss: 0.3469 - acc: 0.8436 - val_loss: 1.0926 - val_acc: 0.6934\n",
      "Epoch 286/300\n",
      "3587/3587 [==============================] - 1s 163us/step - loss: 0.3315 - acc: 0.8500 - val_loss: 1.0905 - val_acc: 0.7023\n",
      "Epoch 287/300\n",
      "3587/3587 [==============================] - 1s 164us/step - loss: 0.3309 - acc: 0.8511 - val_loss: 1.0920 - val_acc: 0.6979\n",
      "Epoch 288/300\n",
      "3587/3587 [==============================] - 1s 166us/step - loss: 0.3357 - acc: 0.8464 - val_loss: 1.1290 - val_acc: 0.6990\n",
      "Epoch 289/300\n",
      "3587/3587 [==============================] - 1s 166us/step - loss: 0.3507 - acc: 0.8419 - val_loss: 1.0758 - val_acc: 0.7057\n",
      "Epoch 290/300\n",
      "3587/3587 [==============================] - 1s 164us/step - loss: 0.3577 - acc: 0.8430 - val_loss: 1.0904 - val_acc: 0.7113\n",
      "Epoch 291/300\n",
      "3587/3587 [==============================] - 1s 165us/step - loss: 0.3390 - acc: 0.8439 - val_loss: 1.0916 - val_acc: 0.7046\n",
      "Epoch 292/300\n",
      "3587/3587 [==============================] - 1s 168us/step - loss: 0.3340 - acc: 0.8525 - val_loss: 1.1123 - val_acc: 0.7035\n",
      "Epoch 293/300\n",
      "3587/3587 [==============================] - 1s 169us/step - loss: 0.3346 - acc: 0.8517 - val_loss: 1.0972 - val_acc: 0.6923\n",
      "Epoch 294/300\n",
      "3587/3587 [==============================] - 1s 165us/step - loss: 0.3375 - acc: 0.8488 - val_loss: 1.1246 - val_acc: 0.6990\n",
      "Epoch 295/300\n",
      "3587/3587 [==============================] - 1s 164us/step - loss: 0.3377 - acc: 0.8500 - val_loss: 1.1100 - val_acc: 0.6968\n",
      "Epoch 296/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3587/3587 [==============================] - 1s 151us/step - loss: 0.3314 - acc: 0.8482 - val_loss: 1.0982 - val_acc: 0.6901\n",
      "Epoch 297/300\n",
      "3587/3587 [==============================] - 1s 142us/step - loss: 0.3250 - acc: 0.8548 - val_loss: 1.1140 - val_acc: 0.6968\n",
      "Epoch 298/300\n",
      "3587/3587 [==============================] - 1s 145us/step - loss: 0.3371 - acc: 0.8500 - val_loss: 1.1270 - val_acc: 0.7057\n",
      "Epoch 299/300\n",
      "3587/3587 [==============================] - 1s 146us/step - loss: 0.3418 - acc: 0.8478 - val_loss: 1.1573 - val_acc: 0.6990\n",
      "Epoch 300/300\n",
      "3587/3587 [==============================] - 1s 146us/step - loss: 0.3353 - acc: 0.8478 - val_loss: 1.0504 - val_acc: 0.7001\n"
     ]
    }
   ],
   "source": [
    "checker = classifier.fit(X_train, Y_train, batch_size=32, epochs=300, validation_data = (X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
