{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "import keras\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_E6oV3lV.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29720</td>\n",
       "      <td>29720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2242</td>\n",
       "      <td>2242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  tweet\n",
       "label              \n",
       "0      29720  29720\n",
       "1       2242   2242"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = df.query('label==1').sample(frac=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2242, 3)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29720</td>\n",
       "      <td>29720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4484</td>\n",
       "      <td>4484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  tweet\n",
       "label              \n",
       "0      29720  29720\n",
       "1       4484   4484"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_df = pd.concat([df,df1],ignore_index=True)\n",
    "n_df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_class_0, count_class_1 = df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_class_0 =  df.query('label==0')\n",
    "df_class_1 =  df.query('label==1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_class_0_under = df_class_0.sample(count_class_1)\n",
    "df_under = pd.concat([df_class_0_under, df_class_1],ignore_index=True ,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4484, 3)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_under.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2242</td>\n",
       "      <td>2242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2242</td>\n",
       "      <td>2242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  tweet\n",
       "label             \n",
       "0      2242   2242\n",
       "1      2242   2242"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_under.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df_under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df['tweet']\n",
    "Y = df['label']\n",
    "Y_org = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "max_features = 10000\n",
    "tokenizer = Tokenizer(num_words=max_features, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', split=' ', lower=True, char_level=False, oov_token=None)\n",
    "tokenizer.fit_on_texts(X.values)\n",
    "X = tokenizer.texts_to_sequences(X.values)\n",
    "\n",
    "# add padding\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "X = pad_sequences(X, maxlen=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' @user #cuandojuegachilemepongo   ð\\x9f\\x92\\x83 saaaaaaaaa shhhhhhhe iiiiiiið\\x9f\\x87¨ð\\x9f\\x87±ð\\x9f\\x87¨ð\\x9f\\x87±ð\\x9f\\x87¨ð\\x9f\\x87±ð\\x9f\\x87¨ð\\x9f\\x87±ð\\x9f\\x87¨ð\\x9f\\x87± #vamoschile #vamoschilecarajo #copaamerica  â\\x9d¤ï¸\\x8f'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df['tweet'], key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shivam/.conda/envs/my_root/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 35)\n",
    "pca.fit(X)\n",
    "X = pca.transform(X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efd3c861518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.cumsum(pca.explained_variance_ratio_)*100)\n",
    "plt.xlabel(\"No. of components\")\n",
    "plt.ylabel(\"cummulative explained Variance\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.2, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units= 20,kernel_initializer= 'uniform', activation='relu' ,input_dim =X.shape[1]))\n",
    "classifier.add(Dropout(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.add(Dense(units= 20,kernel_initializer= 'uniform', activation='relu'))\n",
    "classifier.add(Dropout(0.1))\n",
    "classifier.add(Dense(units= 20,kernel_initializer= 'uniform', activation='relu'))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(2,kernel_initializer='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shivam/.conda/envs/my_root/lib/python3.6/site-packages/ipykernel_launcher.py:5: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \"\"\"\n",
      "/home/shivam/.conda/envs/my_root/lib/python3.6/site-packages/ipykernel_launcher.py:6: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "y_e = OneHotEncoder()\n",
    "Y_train_org = Y_train\n",
    "Y_test_org = Y_test\n",
    "Y_train = Y_train.reshape(-1, 1)\n",
    "Y_test = Y_test.reshape(-1, 1)\n",
    "y_e.fit(Y_train)\n",
    "Y_train = y_e.transform(Y_train)\n",
    "Y_test = y_e.transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3587x2 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3587 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<897x2 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 897 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3587 samples, validate on 897 samples\n",
      "Epoch 1/100\n",
      "3587/3587 [==============================] - 1s 312us/step - loss: 0.6889 - acc: 0.5605 - val_loss: 0.6610 - val_acc: 0.6650\n",
      "Epoch 2/100\n",
      "3587/3587 [==============================] - 1s 155us/step - loss: 0.6442 - acc: 0.6512 - val_loss: 0.6191 - val_acc: 0.6918\n",
      "Epoch 3/100\n",
      "3587/3587 [==============================] - 1s 163us/step - loss: 0.6301 - acc: 0.6645 - val_loss: 0.6160 - val_acc: 0.6912\n",
      "Epoch 4/100\n",
      "3587/3587 [==============================] - 1s 163us/step - loss: 0.6272 - acc: 0.6674 - val_loss: 0.6129 - val_acc: 0.7007\n",
      "Epoch 5/100\n",
      "3587/3587 [==============================] - 1s 165us/step - loss: 0.6253 - acc: 0.6735 - val_loss: 0.6125 - val_acc: 0.7029\n",
      "Epoch 6/100\n",
      "3587/3587 [==============================] - 1s 165us/step - loss: 0.6216 - acc: 0.6735 - val_loss: 0.6101 - val_acc: 0.6990\n",
      "Epoch 7/100\n",
      "3587/3587 [==============================] - 1s 163us/step - loss: 0.6184 - acc: 0.6759 - val_loss: 0.6086 - val_acc: 0.7040\n",
      "Epoch 8/100\n",
      "3587/3587 [==============================] - 1s 166us/step - loss: 0.6149 - acc: 0.6820 - val_loss: 0.6100 - val_acc: 0.7051\n",
      "Epoch 9/100\n",
      "3587/3587 [==============================] - 1s 164us/step - loss: 0.6090 - acc: 0.6931 - val_loss: 0.6075 - val_acc: 0.6984\n",
      "Epoch 10/100\n",
      "3587/3587 [==============================] - 1s 165us/step - loss: 0.6120 - acc: 0.6892 - val_loss: 0.6048 - val_acc: 0.6940\n",
      "Epoch 11/100\n",
      "3587/3587 [==============================] - 1s 164us/step - loss: 0.6042 - acc: 0.6911 - val_loss: 0.6048 - val_acc: 0.6945\n",
      "Epoch 12/100\n",
      "3587/3587 [==============================] - 1s 163us/step - loss: 0.6012 - acc: 0.6953 - val_loss: 0.5992 - val_acc: 0.6934\n",
      "Epoch 13/100\n",
      "3587/3587 [==============================] - 1s 166us/step - loss: 0.6018 - acc: 0.6924 - val_loss: 0.5953 - val_acc: 0.7035\n",
      "Epoch 14/100\n",
      "3587/3587 [==============================] - 1s 177us/step - loss: 0.5959 - acc: 0.7056 - val_loss: 0.5923 - val_acc: 0.7051\n",
      "Epoch 15/100\n",
      "3587/3587 [==============================] - 1s 211us/step - loss: 0.5946 - acc: 0.7064 - val_loss: 0.5927 - val_acc: 0.7090\n",
      "Epoch 16/100\n",
      "3587/3587 [==============================] - 1s 172us/step - loss: 0.5917 - acc: 0.7030 - val_loss: 0.5928 - val_acc: 0.7051\n",
      "Epoch 17/100\n",
      "3587/3587 [==============================] - 1s 171us/step - loss: 0.5867 - acc: 0.7110 - val_loss: 0.5886 - val_acc: 0.7135\n",
      "Epoch 18/100\n",
      "3587/3587 [==============================] - 1s 183us/step - loss: 0.5849 - acc: 0.7142 - val_loss: 0.5862 - val_acc: 0.7152\n",
      "Epoch 19/100\n",
      "3587/3587 [==============================] - 1s 173us/step - loss: 0.5814 - acc: 0.7162 - val_loss: 0.5843 - val_acc: 0.7135\n",
      "Epoch 20/100\n",
      "3587/3587 [==============================] - 1s 200us/step - loss: 0.5727 - acc: 0.7207 - val_loss: 0.5833 - val_acc: 0.7140\n",
      "Epoch 21/100\n",
      "3587/3587 [==============================] - 1s 195us/step - loss: 0.5750 - acc: 0.7158 - val_loss: 0.5841 - val_acc: 0.7124\n",
      "Epoch 22/100\n",
      "3587/3587 [==============================] - 1s 373us/step - loss: 0.5686 - acc: 0.7275 - val_loss: 0.5817 - val_acc: 0.7207\n",
      "Epoch 23/100\n",
      "3587/3587 [==============================] - 1s 172us/step - loss: 0.5677 - acc: 0.7243 - val_loss: 0.5744 - val_acc: 0.7185\n",
      "Epoch 24/100\n",
      "3587/3587 [==============================] - 1s 204us/step - loss: 0.5628 - acc: 0.7290 - val_loss: 0.5700 - val_acc: 0.7269\n",
      "Epoch 25/100\n",
      "3587/3587 [==============================] - 1s 198us/step - loss: 0.5577 - acc: 0.7324 - val_loss: 0.5753 - val_acc: 0.7202\n",
      "Epoch 26/100\n",
      "3587/3587 [==============================] - 1s 158us/step - loss: 0.5575 - acc: 0.7349 - val_loss: 0.5693 - val_acc: 0.7202\n",
      "Epoch 27/100\n",
      "3587/3587 [==============================] - 1s 158us/step - loss: 0.5535 - acc: 0.7339 - val_loss: 0.5597 - val_acc: 0.7336\n",
      "Epoch 28/100\n",
      "3587/3587 [==============================] - 1s 153us/step - loss: 0.5528 - acc: 0.7325 - val_loss: 0.5722 - val_acc: 0.7235\n",
      "Epoch 29/100\n",
      "3587/3587 [==============================] - 1s 154us/step - loss: 0.5495 - acc: 0.7345 - val_loss: 0.5598 - val_acc: 0.7358\n",
      "Epoch 30/100\n",
      "3587/3587 [==============================] - 1s 159us/step - loss: 0.5458 - acc: 0.7409 - val_loss: 0.5600 - val_acc: 0.7291\n",
      "Epoch 31/100\n",
      "3587/3587 [==============================] - 1s 180us/step - loss: 0.5438 - acc: 0.7388 - val_loss: 0.5560 - val_acc: 0.7336\n",
      "Epoch 32/100\n",
      "3587/3587 [==============================] - 1s 162us/step - loss: 0.5424 - acc: 0.7425 - val_loss: 0.5562 - val_acc: 0.7291\n",
      "Epoch 33/100\n",
      "3587/3587 [==============================] - 1s 156us/step - loss: 0.5361 - acc: 0.7434 - val_loss: 0.5530 - val_acc: 0.7336\n",
      "Epoch 34/100\n",
      "3587/3587 [==============================] - 1s 162us/step - loss: 0.5320 - acc: 0.7431 - val_loss: 0.5580 - val_acc: 0.7330\n",
      "Epoch 35/100\n",
      "3587/3587 [==============================] - 1s 161us/step - loss: 0.5272 - acc: 0.7513 - val_loss: 0.5568 - val_acc: 0.7380\n",
      "Epoch 36/100\n",
      "3587/3587 [==============================] - 1s 166us/step - loss: 0.5296 - acc: 0.7506 - val_loss: 0.5547 - val_acc: 0.7230\n",
      "Epoch 37/100\n",
      "3587/3587 [==============================] - 1s 157us/step - loss: 0.5301 - acc: 0.7543 - val_loss: 0.5533 - val_acc: 0.7397\n",
      "Epoch 38/100\n",
      "3587/3587 [==============================] - 1s 158us/step - loss: 0.5197 - acc: 0.7563 - val_loss: 0.5498 - val_acc: 0.7391\n",
      "Epoch 39/100\n",
      "3587/3587 [==============================] - 1s 193us/step - loss: 0.5187 - acc: 0.7491 - val_loss: 0.5508 - val_acc: 0.7391\n",
      "Epoch 40/100\n",
      "3587/3587 [==============================] - 1s 208us/step - loss: 0.5211 - acc: 0.7477 - val_loss: 0.5532 - val_acc: 0.7464\n",
      "Epoch 41/100\n",
      "3587/3587 [==============================] - 1s 180us/step - loss: 0.5218 - acc: 0.7487 - val_loss: 0.5585 - val_acc: 0.7402\n",
      "Epoch 42/100\n",
      "3587/3587 [==============================] - 1s 158us/step - loss: 0.5123 - acc: 0.7636 - val_loss: 0.5566 - val_acc: 0.7358\n",
      "Epoch 43/100\n",
      "3587/3587 [==============================] - 1s 157us/step - loss: 0.5171 - acc: 0.7495 - val_loss: 0.5464 - val_acc: 0.7492\n",
      "Epoch 44/100\n",
      "3587/3587 [==============================] - 1s 185us/step - loss: 0.5129 - acc: 0.7545 - val_loss: 0.5501 - val_acc: 0.7458\n",
      "Epoch 45/100\n",
      "3587/3587 [==============================] - 1s 190us/step - loss: 0.5153 - acc: 0.7544 - val_loss: 0.5515 - val_acc: 0.7402\n",
      "Epoch 46/100\n",
      "3587/3587 [==============================] - 1s 197us/step - loss: 0.5091 - acc: 0.7584 - val_loss: 0.5505 - val_acc: 0.7525\n",
      "Epoch 47/100\n",
      "3587/3587 [==============================] - 1s 164us/step - loss: 0.5076 - acc: 0.7615 - val_loss: 0.5523 - val_acc: 0.7536\n",
      "Epoch 48/100\n",
      "3587/3587 [==============================] - 1s 157us/step - loss: 0.5153 - acc: 0.7595 - val_loss: 0.5504 - val_acc: 0.7436\n",
      "Epoch 49/100\n",
      "3587/3587 [==============================] - 1s 156us/step - loss: 0.5092 - acc: 0.7576 - val_loss: 0.5500 - val_acc: 0.7486\n",
      "Epoch 50/100\n",
      "3587/3587 [==============================] - 1s 156us/step - loss: 0.5046 - acc: 0.7597 - val_loss: 0.5477 - val_acc: 0.7520\n",
      "Epoch 51/100\n",
      "3587/3587 [==============================] - 1s 162us/step - loss: 0.5142 - acc: 0.7577 - val_loss: 0.5471 - val_acc: 0.7469\n",
      "Epoch 52/100\n",
      "3587/3587 [==============================] - 1s 169us/step - loss: 0.4988 - acc: 0.7708 - val_loss: 0.5547 - val_acc: 0.7453\n",
      "Epoch 53/100\n",
      "3587/3587 [==============================] - 1s 165us/step - loss: 0.4989 - acc: 0.7639 - val_loss: 0.5482 - val_acc: 0.7547\n",
      "Epoch 54/100\n",
      "3587/3587 [==============================] - 1s 168us/step - loss: 0.5093 - acc: 0.7607 - val_loss: 0.5589 - val_acc: 0.7408\n",
      "Epoch 55/100\n",
      "3587/3587 [==============================] - 1s 168us/step - loss: 0.5000 - acc: 0.7654 - val_loss: 0.5474 - val_acc: 0.7492\n",
      "Epoch 56/100\n",
      "3587/3587 [==============================] - 1s 166us/step - loss: 0.5017 - acc: 0.7681 - val_loss: 0.5473 - val_acc: 0.7525\n",
      "Epoch 57/100\n",
      "3587/3587 [==============================] - 1s 162us/step - loss: 0.5151 - acc: 0.7619 - val_loss: 0.5364 - val_acc: 0.7559\n",
      "Epoch 58/100\n",
      "3587/3587 [==============================] - 1s 156us/step - loss: 0.5072 - acc: 0.7632 - val_loss: 0.5456 - val_acc: 0.7419\n",
      "Epoch 59/100\n",
      "3587/3587 [==============================] - 1s 157us/step - loss: 0.5023 - acc: 0.7590 - val_loss: 0.5411 - val_acc: 0.7536\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3587/3587 [==============================] - 1s 153us/step - loss: 0.5014 - acc: 0.7621 - val_loss: 0.5460 - val_acc: 0.7525\n",
      "Epoch 61/100\n",
      "3587/3587 [==============================] - 1s 154us/step - loss: 0.4966 - acc: 0.7675 - val_loss: 0.5417 - val_acc: 0.7492\n",
      "Epoch 62/100\n",
      "3587/3587 [==============================] - 1s 156us/step - loss: 0.4935 - acc: 0.7720 - val_loss: 0.5428 - val_acc: 0.7458\n",
      "Epoch 63/100\n",
      "3587/3587 [==============================] - 1s 152us/step - loss: 0.5069 - acc: 0.7611 - val_loss: 0.5485 - val_acc: 0.7414\n",
      "Epoch 64/100\n",
      "3587/3587 [==============================] - 1s 158us/step - loss: 0.4957 - acc: 0.7675 - val_loss: 0.5464 - val_acc: 0.7397\n",
      "Epoch 65/100\n",
      "3587/3587 [==============================] - 1s 163us/step - loss: 0.4952 - acc: 0.7648 - val_loss: 0.5409 - val_acc: 0.7425\n",
      "Epoch 66/100\n",
      "3587/3587 [==============================] - 1s 161us/step - loss: 0.5016 - acc: 0.7672 - val_loss: 0.5525 - val_acc: 0.7430\n",
      "Epoch 67/100\n",
      "3587/3587 [==============================] - 1s 157us/step - loss: 0.4953 - acc: 0.7745 - val_loss: 0.5521 - val_acc: 0.7469\n",
      "Epoch 68/100\n",
      "3587/3587 [==============================] - 1s 164us/step - loss: 0.4942 - acc: 0.7675 - val_loss: 0.5454 - val_acc: 0.7391\n",
      "Epoch 69/100\n",
      "3587/3587 [==============================] - 1s 155us/step - loss: 0.4875 - acc: 0.7725 - val_loss: 0.5394 - val_acc: 0.7514\n",
      "Epoch 70/100\n",
      "3587/3587 [==============================] - 1s 165us/step - loss: 0.4827 - acc: 0.7717 - val_loss: 0.5423 - val_acc: 0.7436\n",
      "Epoch 71/100\n",
      "3587/3587 [==============================] - 1s 155us/step - loss: 0.4918 - acc: 0.7671 - val_loss: 0.5413 - val_acc: 0.7475\n",
      "Epoch 72/100\n",
      "3587/3587 [==============================] - 1s 156us/step - loss: 0.5005 - acc: 0.7598 - val_loss: 0.5426 - val_acc: 0.7514\n",
      "Epoch 73/100\n",
      "3587/3587 [==============================] - 1s 153us/step - loss: 0.4843 - acc: 0.7697 - val_loss: 0.5446 - val_acc: 0.7480\n",
      "Epoch 74/100\n",
      "3587/3587 [==============================] - 1s 164us/step - loss: 0.4966 - acc: 0.7671 - val_loss: 0.5385 - val_acc: 0.7503\n",
      "Epoch 75/100\n",
      "3587/3587 [==============================] - 1s 166us/step - loss: 0.4809 - acc: 0.7714 - val_loss: 0.5434 - val_acc: 0.7503\n",
      "Epoch 76/100\n",
      "3587/3587 [==============================] - 1s 155us/step - loss: 0.4882 - acc: 0.7681 - val_loss: 0.5377 - val_acc: 0.7480\n",
      "Epoch 77/100\n",
      "3587/3587 [==============================] - 1s 160us/step - loss: 0.4830 - acc: 0.7779 - val_loss: 0.5381 - val_acc: 0.7547\n",
      "Epoch 78/100\n",
      "3587/3587 [==============================] - 1s 156us/step - loss: 0.4931 - acc: 0.7623 - val_loss: 0.5359 - val_acc: 0.7536\n",
      "Epoch 79/100\n",
      "3587/3587 [==============================] - 1s 156us/step - loss: 0.4896 - acc: 0.7685 - val_loss: 0.5522 - val_acc: 0.7458\n",
      "Epoch 80/100\n",
      "3587/3587 [==============================] - 1s 156us/step - loss: 0.4929 - acc: 0.7725 - val_loss: 0.5534 - val_acc: 0.7486\n",
      "Epoch 81/100\n",
      "3587/3587 [==============================] - 1s 153us/step - loss: 0.4917 - acc: 0.7713 - val_loss: 0.5388 - val_acc: 0.7525\n",
      "Epoch 82/100\n",
      "3587/3587 [==============================] - 1s 168us/step - loss: 0.4916 - acc: 0.7595 - val_loss: 0.5414 - val_acc: 0.7503\n",
      "Epoch 83/100\n",
      "3587/3587 [==============================] - 1s 160us/step - loss: 0.4916 - acc: 0.7646 - val_loss: 0.5509 - val_acc: 0.7525\n",
      "Epoch 84/100\n",
      "3587/3587 [==============================] - 1s 159us/step - loss: 0.4871 - acc: 0.7729 - val_loss: 0.5365 - val_acc: 0.7547\n",
      "Epoch 85/100\n",
      "3587/3587 [==============================] - 1s 162us/step - loss: 0.4850 - acc: 0.7736 - val_loss: 0.5422 - val_acc: 0.7570\n",
      "Epoch 86/100\n",
      "3587/3587 [==============================] - 1s 157us/step - loss: 0.4907 - acc: 0.7678 - val_loss: 0.5401 - val_acc: 0.7547\n",
      "Epoch 87/100\n",
      "3587/3587 [==============================] - 1s 154us/step - loss: 0.4879 - acc: 0.7725 - val_loss: 0.5445 - val_acc: 0.7469\n",
      "Epoch 88/100\n",
      "3587/3587 [==============================] - 1s 165us/step - loss: 0.4813 - acc: 0.7767 - val_loss: 0.5451 - val_acc: 0.7536\n",
      "Epoch 89/100\n",
      "3587/3587 [==============================] - 1s 164us/step - loss: 0.4755 - acc: 0.7789 - val_loss: 0.5425 - val_acc: 0.7469\n",
      "Epoch 90/100\n",
      "3587/3587 [==============================] - 1s 166us/step - loss: 0.4770 - acc: 0.7803 - val_loss: 0.5516 - val_acc: 0.7469\n",
      "Epoch 91/100\n",
      "3587/3587 [==============================] - 1s 164us/step - loss: 0.4771 - acc: 0.7800 - val_loss: 0.5411 - val_acc: 0.7525\n",
      "Epoch 92/100\n",
      "3587/3587 [==============================] - 1s 164us/step - loss: 0.4852 - acc: 0.7685 - val_loss: 0.5355 - val_acc: 0.7570\n",
      "Epoch 93/100\n",
      "3587/3587 [==============================] - 1s 160us/step - loss: 0.4923 - acc: 0.7687 - val_loss: 0.5464 - val_acc: 0.7469\n",
      "Epoch 94/100\n",
      "3587/3587 [==============================] - 1s 157us/step - loss: 0.4781 - acc: 0.7717 - val_loss: 0.5477 - val_acc: 0.7480\n",
      "Epoch 95/100\n",
      "3587/3587 [==============================] - 1s 178us/step - loss: 0.4727 - acc: 0.7823 - val_loss: 0.5464 - val_acc: 0.7469\n",
      "Epoch 96/100\n",
      "3587/3587 [==============================] - 1s 161us/step - loss: 0.4866 - acc: 0.7747 - val_loss: 0.5579 - val_acc: 0.7514\n",
      "Epoch 97/100\n",
      "3587/3587 [==============================] - 1s 180us/step - loss: 0.4851 - acc: 0.7754 - val_loss: 0.5482 - val_acc: 0.7536\n",
      "Epoch 98/100\n",
      "3587/3587 [==============================] - 1s 179us/step - loss: 0.4716 - acc: 0.7788 - val_loss: 0.5467 - val_acc: 0.7514\n",
      "Epoch 99/100\n",
      "3587/3587 [==============================] - 1s 170us/step - loss: 0.4814 - acc: 0.7767 - val_loss: 0.5493 - val_acc: 0.7525\n",
      "Epoch 100/100\n",
      "3587/3587 [==============================] - 1s 171us/step - loss: 0.4798 - acc: 0.7713 - val_loss: 0.5567 - val_acc: 0.7492\n"
     ]
    }
   ],
   "source": [
    "checker = classifier.fit(X_train, Y_train, batch_size=32, epochs=100, validation_data = (X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred_test_label = classifier.predict(X_test)\n",
    "y_pred_test=np.argmax(Y_pred_test_label,axis =1)\n",
    "y_pred_test\n",
    "Y_pred_train_label = classifier.predict(X_train)\n",
    "y_pred_train = np.argmax(Y_pred_train_label,axis=1)\n",
    "Y_test_true = Y_test_org.astype(np.int)\n",
    "Y_train_true = Y_train_org.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.72      0.74       443\n",
      "          1       0.74      0.78      0.76       454\n",
      "\n",
      "avg / total       0.75      0.75      0.75       897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test_true,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.75      0.80      1799\n",
      "          1       0.78      0.87      0.82      1788\n",
      "\n",
      "avg / total       0.81      0.81      0.81      3587\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_train_true,y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:  \n",
      " [[1295  240]\n",
      " [ 504 1548]]\n",
      "\n",
      "Test:  \n",
      " [[288 111]\n",
      " [155 343]]\n"
     ]
    }
   ],
   "source": [
    "### for softmax function\n",
    "print(\"TRAIN:  \\n\",confusion_matrix(y_pred_train,Y_train_true))\n",
    "print(\"\\nTest:  \\n\",confusion_matrix(y_pred_test,Y_test_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:  \n",
      " [[1358  241]\n",
      " [ 441 1547]]\n",
      "\n",
      "Test:  \n",
      " [[317  99]\n",
      " [126 355]]\n"
     ]
    }
   ],
   "source": [
    "### for sigmoid function\n",
    "print(\"TRAIN:  \\n\",confusion_matrix(y_pred_train,Y_train_true))\n",
    "print(\"\\nTest:  \\n\",confusion_matrix(y_pred_test,Y_test_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
